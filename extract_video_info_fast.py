#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OPTIMIZED Playwright skript pro rychl√© vyhled√°v√°n√≠ vide√≠ na Google a extrakci informac√≠ z Novinky.cz.
- Zkr√°cen√© ƒçekac√≠ doby
- Concurrent processing (v√≠ce vide√≠ souƒçasnƒõ)
- Optimalizovan√© vyhled√°v√°n√≠
"""

import asyncio
import pandas as pd
import time
import random
from playwright.async_api import async_playwright
import csv
import sys
import os
import urllib.parse
import json
from concurrent.futures import ThreadPoolExecutor

class FastVideoInfoExtractor:
    def __init__(self, csv_file, output_file, max_concurrent=2, retry_failed=True):  # Sn√≠≈æeno na 2 kv≈Øli anti-bot
        self.csv_file = csv_file
        self.output_file = output_file
        self.data = None
        self.results = []
        self.max_concurrent = max_concurrent
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.progress_file = "progress.json"
        self.retry_failed = retry_failed
        self.failed_videos = []  # Seznam vide√≠, kter√° selhala
        
        # Seznam r≈Øzn√Ωch User-Agent pro rotaci
        self.user_agents = [
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        ]
        
        # Index pro rotaci User-Agent
        self.current_user_agent_index = 0
        
    def update_progress(self, current, total, status="processing", message=None):
        """Aktualizuje progress soubor."""
        try:
            progress_data = {
                "current": current,
                "total": total,
                "status": status,
                "message": message or f"Zpracov√°no {current} z {total} vide√≠",
                "percentage": round((current / total * 100), 1) if total > 0 else 0
            }
            with open(self.progress_file, 'w', encoding='utf-8') as f:
                json.dump(progress_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"Chyba p≈ôi aktualizaci progress: {e}")
        
    def get_next_user_agent(self):
        """Vr√°t√≠ dal≈°√≠ User-Agent z rotace."""
        user_agent = self.user_agents[self.current_user_agent_index]
        self.current_user_agent_index = (self.current_user_agent_index + 1) % len(self.user_agents)
        return user_agent
    
    async def load_data(self):
        """Naƒçte data z CSV souboru."""
        try:
            df = pd.read_csv(self.csv_file, encoding='utf-8', sep=';', quotechar='"', on_bad_lines='skip')
            print(f"Naƒçteno {len(df)} vide√≠ z {self.csv_file}")
            
            # Filtrov√°n√≠ vide√≠ s Views >= 1000
            df_filtered = df[df['Views'] >= 1000].copy()
            print(f"Po filtrov√°n√≠ (Views >= 1000): {len(df_filtered)} vide√≠")
            
            if len(df_filtered) == 0:
                print("‚ùå ≈Ω√°dn√° videa nespl≈àuj√≠ krit√©rium Views >= 1000")
                return False
            
            self.data = df_filtered
            return True
            
        except Exception as e:
            print(f"Chyba p≈ôi naƒç√≠t√°n√≠ dat: {e}")
            return False
    
    async def search_on_seznam(self, page, query, max_retries=3):
        """RYCHL√â vyhled√°v√°n√≠ na Seznam.cz s retry mechanismem."""
        for attempt in range(max_retries):
            try:
                search_query = f"{query} site:novinky.cz"
                encoded_query = urllib.parse.quote(search_query)
                search_url = f"https://search.seznam.cz/?q={encoded_query}"
                
                await page.goto(search_url, wait_until="domcontentloaded", timeout=8000)  # Zkr√°ceno na 8s
                await page.wait_for_timeout(300)  # ZKR√ÅCENO na 300ms
                return True
                
            except Exception as e:
                print(f"Pokus {attempt + 1}/{max_retries} selhal: {e}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(0.5)  # Kr√°tk√© ƒçek√°n√≠ p≈ôed retry
                    continue
                print(f"Vyhled√°v√°n√≠ selhalo po {max_retries} pokusech")
                return False
    
    async def find_novinky_link_on_seznam(self, page, video_title):
        """RYCHL√â hled√°n√≠ odkazu na Novinky.cz."""
        try:
            novinky_links = page.locator("a[href*='novinky.cz']")
            
            if await novinky_links.count() > 0:
                best_link = None
                best_score = 0
                
                # Omez√≠me na prvn√≠ch 10 odkaz≈Ø pro rychlost
                for i in range(min(await novinky_links.count(), 10)):
                    link = novinky_links.nth(i)
                    href = await link.get_attribute("href")
                    
                    if href and 'novinky.cz' in href and ('/clanek/' in href or '/video/' in href):
                        link_text = await link.text_content()
                        if link_text:
                            score = self.calculate_similarity(video_title.lower(), link_text.lower())
                            if score > best_score:
                                best_score = score
                                best_link = href
                
                if best_link and best_score > 0.1:  # Ni≈æ≈°√≠ pr√°h pro rychlost
                    return best_link
                    
            return None
                
        except Exception as e:
            print(f"Chyba p≈ôi hled√°n√≠ odkazu: {e}")
            return None
    
    def calculate_similarity(self, text1, text2):
        """Rychl√Ω v√Ωpoƒçet podobnosti."""
        words1 = set(text1.split()[:10])  # Pouze prvn√≠ch 10 slov
        words2 = set(text2.split()[:10])
        
        if not words1 or not words2:
            return 0
        
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        
        return len(intersection) / len(union) if union else 0
    
    async def extract_video_info(self, page, novinky_url, max_retries=3):
        """RYCHL√Å extrakce informac√≠ z Novinky.cz s retry mechanismem."""
        for attempt in range(max_retries):
            try:
                print(f"üåê Naƒç√≠t√°m str√°nku: {novinky_url}")
                await page.goto(novinky_url, wait_until="domcontentloaded", timeout=15000)  # Zv√Ω≈°eno na 15s
                await page.wait_for_timeout(1000)  # Zv√Ω≈°eno na 1s pro lep≈°√≠ naƒçten√≠
                print(f"‚úÖ Str√°nka naƒçtena √∫spƒõ≈°nƒõ")
                
                # Rychl√© p≈ôijet√≠ cookies (pouze prvn√≠ pokus)
                if attempt == 0:
                    try:
                        cookie_button = page.locator("button[data-testid='cw-button-agree-with-ads'], button:has-text('Souhlas√≠m')")
                        if await cookie_button.count() > 0:
                            await cookie_button.click()
                            await page.wait_for_timeout(300)  # ZKR√ÅCENO na 300ms
                    except:
                        pass
                
                # ROZ≈†√ç≈òEN√â hled√°n√≠ zdroj≈Ø - v√≠ce strategi√≠
                video_info = None
                
                # 1. Hled√°n√≠ pomoc√≠ r≈Øzn√Ωch selektor≈Ø pro zdroj
                selectors_to_try = [
                    "span.f_bJ",  # P≈Øvodn√≠ selektor - hlavn√≠ c√≠l
                    "div.ogm-container span.f_bJ",  # V ogm-container
                    "div.ogm-main-media__container span.f_bJ",  # V media kontejneru
                    "p.c_br span.f_bJ",  # V odstavci s t≈ô√≠dou c_br
                    "span.f_bJ",  # Obecnƒõ span.f_bJ
                    "div.ogm-main-media__container span",  # Obecnƒõj≈°√≠ v media kontejneru
                    "*:has-text('Zdroj:')",  # ƒåesk√© "Zdroj:"
                    "*:has-text('Video:')",  # ƒåesk√© "Video:"
                    "*:has-text('Foto:')",   # ƒåesk√© "Foto:"
                    "*:has-text('Autor:')",  # ƒåesk√© "Autor:"
                    "[class*='source']",     # CSS t≈ô√≠da obsahuj√≠c√≠ "source"
                    "[class*='author']",     # CSS t≈ô√≠da obsahuj√≠c√≠ "author"
                    "[class*='credit']",     # CSS t≈ô√≠da obsahuj√≠c√≠ "credit"
                    "figcaption",            # ƒåasto obsahuje autorstvo
                    ".media-source",         # Obvykl√° t≈ô√≠da pro zdroj
                    ".video-source",         # Specificky pro video
                    ".article-source",       # Pro ƒçl√°nky
                ]
                
                for selector in selectors_to_try:
                    try:
                        elements = page.locator(selector)
                        count = await elements.count()
                        print(f"üîç Zkou≈°√≠m selektor '{selector}': nalezeno {count} element≈Ø")
                        
                        if count > 0:
                            for i in range(min(count, 3)):  # Max 3 elementy
                                element = elements.nth(i)
                                text = await element.text_content()
                                print(f"   Element {i}: '{text}'")
                                
                                if text and len(text.strip()) > 0:
                                    # Vyƒçisti a validuj text
                                    clean_text = text.strip()
                                    
                                    # Prove≈ô, jestli je to rozumn√° d√©lka pro zdroj
                                    if 3 <= len(clean_text) <= 200:
                                        # Odstranƒõn√≠ prefix≈Ø
                                        for prefix in ['Video:', 'Foto:', 'Zdroj:', 'Autor:']:
                                            if clean_text.startswith(prefix):
                                                clean_text = clean_text[len(prefix):].strip()
                                        
                                        if clean_text and len(clean_text) > 2:
                                            video_info = clean_text
                                            print(f"üéØ Nalezen zdroj pomoc√≠ '{selector}': {clean_text[:50]}...")
                                            break
                            
                            if video_info:
                                break
                                
                    except Exception as e:
                        print(f"‚ùå Chyba p≈ôi zkou≈°en√≠ selektoru '{selector}': {e}")
                        continue  # Zkus dal≈°√≠ selektor
                
                # 2. Pokud st√°le nic, zkusme naj√≠t text obsahuj√≠c√≠ kl√≠ƒçov√° slova
                if not video_info:
                    try:
                        # Hledej text obsahuj√≠c√≠ zn√°m√© zdroje
                        common_sources = ['ƒåT24', 'ƒåTK', 'Reuters', 'AP', 'DPA', 'AFP', 'iStock', 'Shutterstock', 'Getty', 'Profimedia']
                        for source in common_sources:
                            elements = page.locator(f"*:has-text('{source}')")
                            if await elements.count() > 0:
                                element = elements.first
                                text = await element.text_content()
                                if text and source in text:
                                    # Extrahuj jen relevantn√≠ ƒç√°st
                                    lines = text.split('\n')
                                    for line in lines:
                                        if source in line and len(line.strip()) < 100:
                                            video_info = line.strip()
                                            print(f"üéØ Nalezen zdroj podle kl√≠ƒçov√©ho slova '{source}': {video_info}")
                                            break
                                    if video_info:
                                        break
                            if video_info:
                                break
                    except Exception as e:
                        pass
                
                if video_info and video_info.startswith("Video:"):
                    video_info = video_info[6:].strip()
                
                # Pokud m√°me validn√≠ info, vr√°t√≠me ho
                if video_info and len(video_info) > 3:
                    return video_info
                    
            except Exception as e:
                print(f"Pokus {attempt + 1}/{max_retries} extrakce selhal: {e}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(0.3)  # Kr√°tk√© ƒçek√°n√≠ p≈ôed retry
                    continue
                    
        print(f"Extrakce selhala po {max_retries} pokusech")
        return None
    
    async def process_video_worker(self, page, index, row):
        """Worker pro zpracov√°n√≠ jednoho videa s semaforem."""
        async with self.semaphore:
            try:
                video_title = row['N√°zev ƒçl√°nku/videa']
                print(f"[{index+1}] Zpracov√°v√°m: {video_title[:50]}...")
                
                # Vyhled√°n√≠
                if not await self.search_on_seznam(page, video_title):
                    if self.retry_failed:
                        self.failed_videos.append((index, row))
                    return None
                
                # Hled√°n√≠ odkazu
                novinky_url = await self.find_novinky_link_on_seznam(page, video_title)
                if not novinky_url:
                    if self.retry_failed:
                        self.failed_videos.append((index, row))
                    return None
                
                # Extrakce
                extracted_info = await self.extract_video_info(page, novinky_url)
                
                # VALIDACE p≈ôed ulo≈æen√≠m - zabr√°n√≠ HTML kontaminaci
                clean_extracted_info = extracted_info or "N/A"
                if len(clean_extracted_info) > 200:  # P≈ô√≠li≈° dlouh√© = mo≈æn√° HTML kontaminace
                    clean_extracted_info = clean_extracted_info[:100] + "..."
                    
                # Odstranƒõn√≠ HTML tag≈Ø a newlines
                import re
                clean_extracted_info = re.sub(r'<[^>]+>', '', clean_extracted_info)
                clean_extracted_info = clean_extracted_info.replace('\n', ' ').replace('\t', ' ').strip()
                
                result = {
                    'Jm√©no rubriky': str(row['Jm√©no rubriky']).strip(),
                    'N√°zev ƒçl√°nku/videa': str(row['N√°zev ƒçl√°nku/videa']).strip(),
                    'Views': int(row['Views']),
                    'Dokoukanost do 25 %': float(row['Dokoukanost do 25 %']) if pd.notna(row['Dokoukanost do 25 %']) else 0.0,
                    'Dokoukanost do 50 %': float(row['Dokoukanost do 50 %']) if pd.notna(row['Dokoukanost do 50 %']) else 0.0,
                    'Dokoukanost do 75 %': float(row['Dokoukanost do 75 %']) if pd.notna(row['Dokoukanost do 75 %']) else 0.0,
                    'Dokoukanost do 100 %': float(row['Dokoukanost do 100 %']) if pd.notna(row['Dokoukanost do 100 %']) else 0.0,
                    'Extrahovan√© info': clean_extracted_info,
                    'Novinky URL': str(novinky_url).strip()
                }
                
                self.results.append(result)
                print(f"‚úÖ [{index+1}] Hotovo: {extracted_info[:30] if extracted_info else 'N/A'}...")
                
                # Aktualizace progress
                self.update_progress(len(self.results), len(self.data), "processing")
                
                # Anti-bot ƒçek√°n√≠ - mus√≠me b√Ωt pomalej≈°√≠
                await asyncio.sleep(random.uniform(2, 5))  # Pomalej≈°√≠ 2-5s kv≈Øli anti-bot ochranƒõ
                
                return result
                
            except Exception as e:
                print(f"‚ùå [{index+1}] Chyba: {e}")
                if self.retry_failed:
                    self.failed_videos.append((index, row))
                return None
    
    async def retry_failed_videos(self):
        """Zkus√≠ znovu zpracovat videa, kter√° selhala."""
        if not self.failed_videos:
            print("‚úÖ ≈Ω√°dn√° videa k retry")
            return True
            
        print(f"üîÑ Zkou≈°√≠m znovu zpracovat {len(self.failed_videos)} selhan√Ωch vide√≠...")
        
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            page = await browser.new_page()
            
            # Nastaven√≠ User-Agent
            await page.set_extra_http_headers({
                'User-Agent': self.get_next_user_agent()
            })
            
            # Zpracov√°n√≠ selhan√Ωch vide√≠
            for index, row in self.failed_videos:
                try:
                    print(f"üîÑ Retry [{index+1}]: {row['N√°zev ƒçl√°nku/videa'][:50]}...")
                    
                    # Vyhled√°n√≠
                    if not await self.search_on_seznam(page, row['N√°zev ƒçl√°nku/videa']):
                        continue
                    
                    # Hled√°n√≠ odkazu
                    novinky_url = await self.find_novinky_link_on_seznam(page, row['N√°zev ƒçl√°nku/videa'])
                    if not novinky_url:
                        continue
                    
                    # Extrakce
                    extracted_info = await self.extract_video_info(page, novinky_url)
                    
                    # Ulo≈æen√≠ v√Ωsledku
                    clean_extracted_info = extracted_info or "N/A"
                    if len(clean_extracted_info) > 200:
                        clean_extracted_info = clean_extracted_info[:100] + "..."
                    
                    import re
                    clean_extracted_info = re.sub(r'<[^>]+>', '', clean_extracted_info)
                    clean_extracted_info = clean_extracted_info.replace('\n', ' ').replace('\t', ' ').strip()
                    
                    result = {
                        'Jm√©no rubriky': str(row['Jm√©no rubriky']).strip(),
                        'N√°zev ƒçl√°nku/videa': str(row['N√°zev ƒçl√°nku/videa']).strip(),
                        'Views': int(row['Views']),
                        'Dokoukanost do 25 %': float(row['Dokoukanost do 25 %']) if pd.notna(row['Dokoukanost do 25 %']) else 0.0,
                        'Dokoukanost do 50 %': float(row['Dokoukanost do 50 %']) if pd.notna(row['Dokoukanost do 50 %']) else 0.0,
                        'Dokoukanost do 75 %': float(row['Dokoukanost do 75 %']) if pd.notna(row['Dokoukanost do 75 %']) else 0.0,
                        'Dokoukanost do 100 %': float(row['Dokoukanost do 100 %']) if pd.notna(row['Dokoukanost do 100 %']) else 0.0,
                        'Extrahovan√© info': clean_extracted_info,
                        'Novinky URL': str(novinky_url).strip()
                    }
                    
                    self.results.append(result)
                    print(f"‚úÖ Retry [{index+1}] Hotovo: {extracted_info[:30] if extracted_info else 'N/A'}...")
                    
                    # Anti-bot ƒçek√°n√≠
                    await asyncio.sleep(random.uniform(3, 6))
                    
                except Exception as e:
                    print(f"‚ùå Retry [{index+1}] Chyba: {e}")
                    continue
            
            await browser.close()
        
        print(f"‚úÖ Retry dokonƒçen. Celkem v√Ωsledk≈Ø: {len(self.results)}")
        return True
    
    async def run_concurrent(self, max_videos=None):
        """Spust√≠ RYCHL√â concurrent zpracov√°n√≠."""
        if not await self.load_data():
            return False
        
        data_to_process = self.data
        if max_videos:
            data_to_process = self.data.head(max_videos)
        
        print(f"üöÄ Spou≈°t√≠m rychl√© zpracov√°n√≠ {len(data_to_process)} vide√≠ s {self.max_concurrent} concurrent workers")
        
        # Inicializace progress
        self.update_progress(0, len(data_to_process), "starting", "Spou≈°t√≠m zpracov√°n√≠...")
        
        async with async_playwright() as p:
            # Detekce prost≈ôed√≠ - cloud vs lok√°ln√≠
            is_cloud = os.environ.get('RAILWAY_ENVIRONMENT') or os.environ.get('NODE_ENV') == 'production'
            
            if is_cloud:
                # Cloud prost≈ôed√≠ - headless s optimalizacemi pro Novinky.cz
                browser = await p.chromium.launch(
                    headless=True, 
                    slow_mo=200,  # Pomalej≈°√≠ pro stabilitu
                    args=[
                        '--no-sandbox',
                        '--disable-setuid-sandbox',
                        '--disable-dev-shm-usage',
                        '--disable-accelerated-2d-canvas',
                        '--no-first-run',
                        '--no-zygote',
                        '--disable-gpu',
                        '--disable-web-security',
                        '--disable-features=VizDisplayCompositor',
                        '--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
                    ]
                )
            else:
                # Lok√°ln√≠ prost≈ôed√≠ - non-headless pro debugging
                browser = await p.chromium.launch(headless=False, slow_mo=500)
            
            # Vytvo≈ôen√≠ v√≠ce pages pro concurrent processing
            pages = []
            for i in range(self.max_concurrent):
                context = await browser.new_context(user_agent=self.get_next_user_agent())
                page = await context.new_page()
                pages.append(page)
            
            try:
                # Rozdƒõlen√≠ pr√°ce mezi pages
                tasks = []
                for idx, (index, row) in enumerate(data_to_process.iterrows()):
                    page_index = idx % len(pages)
                    page = pages[page_index]
                    task = self.process_video_worker(page, index, row)
                    tasks.append(task)
                
                # Spu≈°tƒõn√≠ v≈°ech task≈Ø souƒçasnƒõ
                results = await asyncio.gather(*tasks, return_exceptions=True)
                
                completed_count = len([r for r in results if r is not None and not isinstance(r, Exception)])
                print(f"‚úÖ Dokonƒçeno! Zpracov√°no {completed_count} vide√≠")
                
                # Fin√°ln√≠ progress update
                self.update_progress(completed_count, len(data_to_process), "completed", f"Dokonƒçeno! Zpracov√°no {completed_count} vide√≠")
                
                # Pr≈Øbƒõ≈æn√© ukl√°d√°n√≠
                await self.save_results()
                
                # Retry selhan√Ωch vide√≠
                if self.retry_failed and self.failed_videos:
                    print(f"üîÑ Spou≈°t√≠m retry pro {len(self.failed_videos)} selhan√Ωch vide√≠...")
                    await self.retry_failed_videos()
                    await self.save_results()
                
            finally:
                await browser.close()
        
        return True
    
    async def save_results(self):
        """Ulo≈æ√≠ v√Ωsledky do CSV."""
        try:
            if self.results:
                df_results = pd.DataFrame(self.results)
                df_results.to_csv(self.output_file, index=False, encoding='utf-8', sep=';')
                print(f"üíæ V√Ωsledky ulo≈æeny: {len(self.results)} z√°znam≈Ø -> {self.output_file}")
        except Exception as e:
            print(f"Chyba p≈ôi ukl√°d√°n√≠: {e}")

async def main():
    """Hlavn√≠ funkce."""
    csv_file = "/Users/david.rynes/Desktop/_DESKTOP/_CODE/statistiky/datasets/20250904T141416_c4f7a567/clean.csv"
    output_file = "/Users/david.rynes/Desktop/_DESKTOP/_CODE/statistiky/datasets/20250904T141416_c4f7a567/extracted.csv"
    
    if not os.path.exists(csv_file):
        print(f"‚ùå Vstupn√≠ soubor {csv_file} neexistuje.")
        return
    
    print("üöÄ" + "=" * 60)
    print("RYCHL√ù SKRIPT PRO EXTRAKCI Z NOVINKY.CZ")
    print("üöÄ" + "=" * 60)
    
    # Vytvo≈ôen√≠ extraktoru s anti-bot ochranou a retry mechanismem
    extractor = FastVideoInfoExtractor(csv_file, output_file, max_concurrent=2, retry_failed=True)  # 2 workers + retry
    
    # Spu≈°tƒõn√≠ rychl√© extrakce - v≈°echna videa
    start_time = time.time()
    success = await extractor.run_concurrent()  # Zpracovat v≈°echna videa
    end_time = time.time()
    
    if success:
        print(f"\n‚ö° RYCHL√Å EXTRAKCE DOKONƒåENA za {end_time - start_time:.1f} sekund! ‚ö°")
    else:
        print(f"\n‚ùå EXTRAKCE SELHALA")

if __name__ == "__main__":
    asyncio.run(main())